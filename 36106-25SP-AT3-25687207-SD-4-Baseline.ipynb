{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ6wc2HE0pke"
      },
      "source": [
        "# **Baseline Notebook**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFVpE17Ahezu"
      },
      "source": [
        "---\n",
        "## Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "!pip install -q utstd\n",
        "\n",
        "from utstd.folders import *\n",
        "from utstd.ipyrenders import *\n",
        "\n",
        "at = AtFolder(\n",
        "    course_code=36106,\n",
        "    assignment=\"AT3\",\n",
        ")\n",
        "at.run()\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ],
      "metadata": {
        "id": "S8jFaNXqvV5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Student Information"
      ],
      "metadata": {
        "id": "Bv9hJ8IO8MTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section and then remove this comment>\n",
        "group_name = \"AT3-group 12\"\n",
        "student_name = \"CEWANG\"\n",
        "student_id = \"25687207\""
      ],
      "metadata": {
        "id": "ot2igNok8NbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h1\", key='group_name', value=group_name)"
      ],
      "metadata": {
        "id": "nMGPhFYunsRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h1\", key='student_name', value=student_name)"
      ],
      "metadata": {
        "id": "NE3R8WY98N_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h1\", key='student_id', value=student_id)"
      ],
      "metadata": {
        "id": "anavsHjV8OM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 0. Python Packages"
      ],
      "metadata": {
        "id": "Is0ghwXODHkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.a Install Additional Packages\n",
        "\n",
        "> If you are using additional packages, you need to install them here using the command: `! pip install <package_name>`"
      ],
      "metadata": {
        "id": "CgTrMfyylVLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q scikit-learn matplotlib seaborn altair"
      ],
      "metadata": {
        "id": "D79tb2V-lVpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.b Import Packages"
      ],
      "metadata": {
        "id": "mXFKfa2tp1ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section and then remove this comment>\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "GBEAwdncnlAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8MNBrC4Zgz6"
      },
      "source": [
        "---\n",
        "## A. Assess Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "# Load data\n",
        "try:\n",
        "  X_train = pd.read_csv(at.folder_path / 'X_train.csv')\n",
        "  y_train = pd.read_csv(at.folder_path / 'y_train.csv')\n",
        "\n",
        "  X_val = pd.read_csv(at.folder_path / 'X_val.csv')\n",
        "  y_val = pd.read_csv(at.folder_path / 'y_val.csv')\n",
        "\n",
        "  X_test = pd.read_csv(at.folder_path / 'X_test.csv')\n",
        "  y_test = pd.read_csv(at.folder_path / 'y_test.csv')\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "id": "OFdr7RAY4x9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "\n",
        "  customers_cleaned = pd.read_csv(at.folder_path / \"data\" / \"customers_cleaned.csv\")\n",
        "  print(\"Customers cleaned data loaded successfully!\")\n",
        "  print(f\"Customers shape: {customers_cleaned.shape}\")\n",
        "\n",
        "  try:\n",
        "    X_train_final = pd.read_csv(at.folder_path / \"X_train_final.csv\")\n",
        "    X_val_final = pd.read_csv(at.folder_path / \"X_val_final.csv\")\n",
        "    X_test_final = pd.read_csv(at.folder_path / \"X_test_final.csv\")\n",
        "    print(\"Preprocessed feature data found!\")\n",
        "  except:\n",
        "    print(\"Preprocessed feature data not found, we'll use customers_cleaned data\")\n",
        "\n",
        "except Exception as e:\n",
        "  print(f\"Error loading data: {e}\")\n",
        "\n",
        "import os\n",
        "print(\"\\nAvailable files in data directory:\")\n",
        "data_dir = at.folder_path / \"data\"\n",
        "if data_dir.exists():\n",
        "    for file in data_dir.iterdir():\n",
        "        print(f\"  - {file.name}\")"
      ],
      "metadata": {
        "id": "zu2uWiAjdiQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.1 Generate Predictions with Baseline Model"
      ],
      "metadata": {
        "id": "4_tQitOfeDXr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mh6epkAThez5"
      },
      "outputs": [],
      "source": [
        "# A.1 Generate Predictions with Baseline Model\n",
        "print(\"=== Baseline K-Means Clustering Model ===\\n\")\n",
        "\n",
        "# Use our existing customer data\n",
        "df = customers_cleaned.copy()\n",
        "\n",
        "# Select numerical features for clustering\n",
        "numerical_features = ['age', 'annual_income', 'number_dependents', 'customer_value_score']\n",
        "print(f\"Selected numerical features for clustering: {numerical_features}\")\n",
        "\n",
        "# Prepare data\n",
        "X_cluster = df[numerical_features].copy()\n",
        "\n",
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_cluster)\n",
        "\n",
        "print(f\"Data prepared for clustering: {X_scaled.shape}\")\n",
        "\n",
        "# Use elbow method to determine optimal number of clusters\n",
        "print(\"\\n=== Elbow Method Analysis ===\\n\")\n",
        "wcss = []  # Within-Cluster Sum of Square\n",
        "silhouette_scores = []\n",
        "k_range = range(2, 11)\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_scaled)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "    # Calculate silhouette score\n",
        "    if k > 1:  # Silhouette score requires at least 2 clusters\n",
        "        silhouette_avg = silhouette_score(X_scaled, kmeans.labels_)\n",
        "        silhouette_scores.append(silhouette_avg)\n",
        "        print(f\"K={k}: WCSS = {kmeans.inertia_:.2f}, Silhouette Score = {silhouette_avg:.4f}\")\n",
        "    else:\n",
        "        print(f\"K={k}: WCSS = {kmeans.inertia_:.2f}\")\n",
        "\n",
        "# Plot elbow method\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(k_range, wcss, 'bo-')\n",
        "plt.xlabel('Number of Clusters (K)')\n",
        "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
        "plt.title('Elbow Method for Optimal K')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(2, 11), silhouette_scores, 'go-')\n",
        "plt.xlabel('Number of Clusters (K)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Analysis for Optimal K')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.2 Selection of Performance Metrics\n",
        "\n",
        "> Provide some explanations on why you believe the performance metrics you chose is appropriate\n"
      ],
      "metadata": {
        "id": "n5ApYC8BeLsB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7We16YIYhez5"
      },
      "outputs": [],
      "source": [
        "print(\"=== Final Baseline Model with K=4 ===\")\n",
        "\n",
        "kmeans_baseline = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
        "baseline_labels = kmeans_baseline.fit_predict(X_scaled)\n",
        "\n",
        "df['cluster'] = baseline_labels\n",
        "\n",
        "print(f\"Baseline model trained with {kmeans_baseline.n_clusters} clusters\")\n",
        "\n",
        "cluster_counts = df['cluster'].value_counts().sort_index()\n",
        "print(\"\\nCluster distribution:\")\n",
        "for cluster, count in cluster_counts.items():\n",
        "    print(f\"Cluster {cluster}: {count} customers ({count/len(df)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\n=== Cluster Profile Analysis ===\")\n",
        "cluster_profile = df.groupby('cluster')[numerical_features].mean()\n",
        "print(cluster_profile.round(2))\n",
        "\n",
        "silhouette_avg = silhouette_score(X_scaled, baseline_labels)\n",
        "calinski_harabasz = calinski_harabasz_score(X_scaled, baseline_labels)\n",
        "davies_bouldin = davies_bouldin_score(X_scaled, baseline_labels)\n",
        "\n",
        "print(f\"\\n=== Model Performance Metrics ===\")\n",
        "print(f\"Silhouette Score: {silhouette_avg:.4f}\")\n",
        "print(f\"Calinski-Harabasz Index: {calinski_harabasz:.2f}\")\n",
        "print(f\"Davies-Bouldin Index: {davies_bouldin:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "df['cluster'].value_counts().sort_index().plot(kind='bar', color='skyblue')\n",
        "plt.title('Cluster Size Distribution')\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Number of Customers')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "for feature in numerical_features:\n",
        "    plt.scatter(df['cluster'], df[feature], alpha=0.6, label=feature)\n",
        "plt.title('Feature Distribution by Cluster')\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Feature Value')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=baseline_labels, cmap='viridis', alpha=0.6)\n",
        "plt.title('PCA Visualization of Clusters')\n",
        "plt.xlabel('First Principal Component')\n",
        "plt.ylabel('Second Principal Component')\n",
        "plt.colorbar(label='Cluster')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance_metrics_explanations = \"\"\"\n",
        "For clustering analysis, I selected three complementary performance metrics:\n",
        "\n",
        "1. **Silhouette Score**: Measures how similar an object is to its own cluster compared to other clusters. Values range from -1 to 1, where higher values indicate better-defined clusters. This is appropriate because it evaluates both cluster cohesion and separation.\n",
        "\n",
        "2. **Calinski-Harabasz Index**: Also known as the Variance Ratio Criterion, this metric measures the ratio between within-cluster dispersion and between-cluster dispersion. Higher values indicate better clustering. It's suitable for our K-means baseline as it works well with Euclidean distance-based algorithms.\n",
        "\n",
        "3. **Davies-Bouldin Index**: Measures the average similarity between each cluster and its most similar cluster. Lower values indicate better clustering. This provides a different perspective by focusing on cluster separation quality.\n",
        "\n",
        "These metrics are appropriate because:\n",
        "- They provide comprehensive evaluation of cluster quality from different angles\n",
        "- They work well with K-means clustering and Euclidean distance\n",
        "- They help validate both cluster cohesion and separation\n",
        "- They are widely accepted in clustering literature and practice\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BiBsv8S_QyD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='performance_metrics_explanations', value=performance_metrics_explanations)"
      ],
      "metadata": {
        "id": "Ln-xOAkgQyLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.3 Baseline Model Performance\n",
        "\n",
        "> Provide some explanations on model performance\n"
      ],
      "metadata": {
        "id": "q43YtqpdeniY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1Q3oxoNhez5"
      },
      "outputs": [],
      "source": [
        "# <Student to fill this section and then remove this comment>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_performance_explanations = \"\"\"\n",
        "Baseline K-means clustering model performance analysis:\n",
        "\n",
        "Model Configuration:**\n",
        "- Algorithm: K-means with K=4 clusters\n",
        "- Features: age, annual_income, number_dependents, customer_value_score\n",
        "- Dataset: 19,963 customers\n",
        "\n",
        "Performance Metrics Analysis:**\n",
        "- **Silhouette Score (0.2911)**: Indicates fair cluster separation. The score is positive but could be improved, suggesting some overlap between clusters.\n",
        "- **Calinski-Harabasz Index (9652.31)**: Very high value indicates excellent between-cluster variance relative to within-cluster variance.\n",
        "- **Davies-Bouldin Index (1.1052)**: Low value indicates good cluster separation with minimal overlap.\n",
        "\n",
        "Cluster Distribution:**\n",
        "The model created 4 well-balanced clusters (22-29% each), avoiding the issue of imbalanced clusters.\n",
        "\n",
        "Cluster Profiles:**\n",
        "- **Cluster 0**: Middle-aged customers with high income, few dependents, high value score\n",
        "- **Cluster 1**: Older customers with highest income, many dependents, high value score\n",
        "- **Cluster 2**: Older customers with low income, moderate dependents, low value score\n",
        "- **Cluster 3**: Younger customers with lowest income, few dependents, lowest value score\n",
        "\n",
        "Overall Assessment:**\n",
        "The baseline model provides a solid foundation with meaningful customer segments. The clusters show clear demographic and socioeconomic patterns. Performance metrics indicate reasonable cluster quality, though there's room for improvement in future iterations.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "b7S2t4bCQ3Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='baseline_performance_explanations', value=baseline_performance_explanations)"
      ],
      "metadata": {
        "id": "Am6ovHycQ3d8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}