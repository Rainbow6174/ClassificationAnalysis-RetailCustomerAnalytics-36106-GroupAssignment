{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ6wc2HE0pke"
      },
      "source": [
        "# **Preparation Notebook**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFVpE17Ahezu"
      },
      "source": [
        "---\n",
        "## Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "!pip install -q utstd\n",
        "\n",
        "from utstd.folders import *\n",
        "from utstd.ipyrenders import *\n",
        "\n",
        "at = AtFolder(\n",
        "    course_code=36106,\n",
        "    assignment=\"AT3\",\n",
        ")\n",
        "at.run()\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ],
      "metadata": {
        "id": "S8jFaNXqvV5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Student Information"
      ],
      "metadata": {
        "id": "ujC3TjlB7-EZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section and then remove this comment>\n",
        "group_name = \"AT3-group 12\"\n",
        "student_name = \"CEWANG\"\n",
        "student_id = \"25687207\""
      ],
      "metadata": {
        "id": "dug0CHu27_wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h1\", key='group_name', value=group_name)"
      ],
      "metadata": {
        "id": "2jXi_XvEuChh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h1\", key='student_name', value=student_name)"
      ],
      "metadata": {
        "id": "SeSMrvjD8AIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h1\", key='student_id', value=student_id)"
      ],
      "metadata": {
        "id": "Utiw0TD68JjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 0. Python Packages"
      ],
      "metadata": {
        "id": "sO3Cb4F0DrGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.a Install Additional Packages\n",
        "\n",
        "> If you are using additional packages, you need to install them here using the command: `! pip install <package_name>`"
      ],
      "metadata": {
        "id": "CgTrMfyylVLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q scikit-learn matplotlib seaborn"
      ],
      "metadata": {
        "id": "D79tb2V-lVpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.b Import Packages"
      ],
      "metadata": {
        "id": "mXFKfa2tp1ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "import pandas as pd\n",
        "import altair as alt"
      ],
      "metadata": {
        "id": "GBEAwdncnlAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "z6GHCFHzHnCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NCwQQFkU3v5"
      },
      "source": [
        "---\n",
        "## A. Feature Selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A.0 Load Data"
      ],
      "metadata": {
        "id": "PXegqMWYt6TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    customers_cleaned = pd.read_csv(at.folder_path / \"data\" / \"customers_cleaned.csv\")\n",
        "    product_cats_cleaned = pd.read_csv(at.folder_path / \"data\" / \"product_cats_cleaned.csv\")\n",
        "    print(\"Loaded cleaned datasets successfully\")\n",
        "    print(f\"Customers shape: {customers_cleaned.shape}\")\n",
        "    print(f\"Product categories shape: {product_cats_cleaned.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading cleaned datasets: {e}\")\n",
        "\n",
        "    customers_cleaned = customers_df\n",
        "    product_cats_cleaned = product_cats_df"
      ],
      "metadata": {
        "id": "FW-0VWj8304m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.1 Approach 1"
      ],
      "metadata": {
        "id": "E18dcL6C3O-4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiroVmhn9_HP"
      },
      "outputs": [],
      "source": [
        "print(\"=== Business-Driven Feature Selection ===\\n\")\n",
        "\n",
        "demographic_features = ['age', 'marital_status', 'number_dependents']\n",
        "socioeconomic_features = ['annual_income', 'education_level', 'occupation', 'homeowner']\n",
        "behavioral_features = []\n",
        "engineered_features = ['age_group', 'income_category', 'lifestyle_segment', 'family_status', 'customer_value_score', 'value_segment']\n",
        "\n",
        "print(\"Key Feature Categories for Customer Segmentation:\")\n",
        "print(f\"1. Demographic Features: {demographic_features}\")\n",
        "print(f\"2. Socioeconomic Features: {socioeconomic_features}\")\n",
        "print(f\"3. Engineered Features: {engineered_features}\")\n",
        "\n",
        "print(\"\\nCorrelation Analysis of Numerical Features:\")\n",
        "numerical_features = customers_cleaned.select_dtypes(include=['number']).columns\n",
        "correlation_matrix = customers_cleaned[numerical_features].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Matrix of Numerical Features')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"High correlation (>0.7) pairs:\")\n",
        "high_corr_pairs = []\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i+1, len(correlation_matrix.columns)):\n",
        "        if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
        "            high_corr_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j],\n",
        "                                  correlation_matrix.iloc[i, j]))\n",
        "            print(f\"  {correlation_matrix.columns[i]} vs {correlation_matrix.columns[j]}: {correlation_matrix.iloc[i, j]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ynIRSpW6KoH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_selection_1_insights = \"\"\"\n",
        "Approach: Business-Driven Feature Selection\n",
        "Rationale: For customer segmentation, we prioritize features that directly describe customer characteristics, behaviors, and value potential.\n",
        "\n",
        "Key Insights from Correlation Analysis:\n",
        "- Identified highly correlated feature pairs that may cause multicollinearity\n",
        "- Customer value score shows moderate correlation with income and education scores (as expected)\n",
        "- Age shows low correlation with other features, making it valuable for segmentation\n",
        "\n",
        "Selected Feature Categories:\n",
        "1. Demographic: Age, marital status, dependents (capture life stage)\n",
        "2. Socioeconomic: Income, education, occupation, homeownership (reflect purchasing power)\n",
        "3. Engineered: Lifestyle segments, value scores (provide business context)\n",
        "\n",
        "Business Justification: These features enable identification of meaningful customer segments like \"Affluent Professionals\", \"Budget-Conscious Families\", etc., which are actionable for marketing strategies.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "poQf_avFPHiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_selection_1_insights', value=feature_selection_1_insights)"
      ],
      "metadata": {
        "id": "7JRXCIVFPHlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.2 Approach 2"
      ],
      "metadata": {
        "id": "m0WdHbsf3vTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Multicollinearity Handling and Final Feature Selection ===\\n\")\n",
        "\n",
        "features_to_remove = [\n",
        "    'income_score',\n",
        "    'age_score',\n",
        "    'education_score', 'homeowner_score', 'occupation_score'\n",
        "]\n",
        "\n",
        "print(\"Features removed due to high correlation:\")\n",
        "for feature in features_to_remove:\n",
        "    print(f\"  - {feature}\")\n",
        "\n",
        "final_features = [\n",
        "\n",
        "    'age', 'marital_status', 'number_dependents',\n",
        "\n",
        "    'annual_income', 'education_level', 'occupation', 'homeowner',\n",
        "\n",
        "    'age_group', 'income_category', 'lifestyle_segment', 'family_status', 'value_segment'\n",
        "]\n",
        "\n",
        "print(f\"\\nFinal selected features ({len(final_features)}):\")\n",
        "for i, feature in enumerate(final_features, 1):\n",
        "    print(f\"  {i:2d}. {feature}\")\n",
        "\n",
        "X_selected = customers_cleaned[final_features].copy()\n",
        "\n",
        "print(f\"\\nSelected dataset shape: {X_selected.shape}\")\n",
        "print(\"\\nData types of selected features:\")\n",
        "print(X_selected.dtypes.value_counts())\n",
        "\n",
        "print(\"\\nMissing values in selected features:\")\n",
        "missing_values = X_selected.isnull().sum()\n",
        "print(missing_values[missing_values > 0])"
      ],
      "metadata": {
        "id": "2aAKCI6v3xbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GE157K3nK4dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_selection_2_insights = \"\"\"\n",
        "Approach: Multicollinearity Handling and Final Feature Selection\n",
        "Rationale: Remove redundant features to improve clustering performance and interpretability.\n",
        "\n",
        "Key Actions:\n",
        "- Removed derived score features that showed perfect correlation with original features\n",
        "- Kept original categorical features (education_level, occupation, homeowner) for better interpretability\n",
        "- Retained engineered business segments that provide actionable insights\n",
        "\n",
        "Final Feature Set (13 features):\n",
        "- Demographic: age, marital_status, number_dependents\n",
        "- Socioeconomic: annual_income, education_level, occupation, homeowner\n",
        "- Engineered: age_group, income_category, lifestyle_segment, family_status, value_segment\n",
        "\n",
        "Benefits:\n",
        "- Eliminates multicollinearity issues\n",
        "- Maintains business interpretability\n",
        "- Provides balanced representation of customer characteristics\n",
        "- Ready for encoding and scaling for clustering algorithms\n",
        "\n",
        "Dataset ready: 19,963 customers × 13 features with no missing values\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZETRSFpiPlYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_selection_2_insights', value=feature_selection_2_insights)"
      ],
      "metadata": {
        "id": "TYTclH9HPlda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.n Approach \"\\<describe_approach_here\\>\"\n",
        "\n",
        "> You can add more cells related to other approaches in this section"
      ],
      "metadata": {
        "id": "x0E3hYLwK-PQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.z Final Selection of Features"
      ],
      "metadata": {
        "id": "j5bbQlUn3635"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = [\n",
        "    'age', 'marital_status', 'number_dependents',\n",
        "    'annual_income', 'education_level', 'occupation', 'homeowner',\n",
        "    'age_group', 'income_category', 'lifestyle_segment', 'family_status', 'value_segment'\n",
        "]\n",
        "\n",
        "print(\"=== FINAL FEATURE SELECTION FOR CUSTOMER CLUSTERING ===\\n\")\n",
        "print(f\"Total features selected: {len(features_list)}\")\n",
        "print(f\"Dataset shape: {X_selected.shape}\")\n",
        "\n",
        "print(\"\\nFeature Categories:\")\n",
        "print(\"1. Demographic (3): age, marital_status, number_dependents\")\n",
        "print(\"2. Socioeconomic (4): annual_income, education_level, occupation, homeowner\")\n",
        "print(\"3. Engineered Segments (5): age_group, income_category, lifestyle_segment, family_status, value_segment\")\n",
        "\n",
        "print(\"\\nData Type Distribution:\")\n",
        "print(X_selected.dtypes.value_counts())\n",
        "\n",
        "print(\"\\nSample of selected data:\")\n",
        "display(X_selected.head(3))"
      ],
      "metadata": {
        "id": "zfC-DLKv4AuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VeRdhcf-K5H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_selection_explanations = \"\"\"\n",
        "Final Feature Selection for Customer Clustering:\n",
        "\n",
        "Selected 12 features across 3 categories:\n",
        "\n",
        "1. DEMOGRAPHIC (Life Stage):\n",
        "   - age: Customer age (numerical)\n",
        "   - marital_status: Marital status (categorical)\n",
        "   - number_dependents: Number of dependents (numerical)\n",
        "\n",
        "2. SOCIOECONOMIC (Purchasing Power):\n",
        "   - annual_income: Yearly income (numerical)\n",
        "   - education_level: Education attainment (ordinal categorical)\n",
        "   - occupation: Job type (categorical)\n",
        "   - homeowner: Homeownership status (binary categorical)\n",
        "\n",
        "3. ENGINEERED SEGMENTS (Business Context):\n",
        "   - age_group: Age categories (categorical)\n",
        "   - income_category: Income brackets (categorical)\n",
        "   - lifestyle_segment: Combined lifestyle classification\n",
        "   - family_status: Family structure\n",
        "   - value_segment: Customer value tier\n",
        "\n",
        "Rationale:\n",
        "- Balanced mix of numerical and categorical features\n",
        "- Eliminated multicollinearity from derived scores\n",
        "- Maintained business interpretability\n",
        "- All features have no missing values\n",
        "- Ready for data transformation and clustering\n",
        "\n",
        "This feature set enables identification of meaningful customer segments for targeted marketing strategies.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "wRkiZf4sPsxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_selection_explanations', value=feature_selection_explanations)"
      ],
      "metadata": {
        "id": "EcG8s40PPs3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## B. Data Cleaning"
      ],
      "metadata": {
        "id": "ErH_bh604mOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrXR7NCLtwxB"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "# Load datasets\n",
        "try:\n",
        "  sales_2022_df = pd.read_csv(at.folder_path / \"sales_2022.csv\")\n",
        "  products_df = pd.read_csv(at.folder_path / \"products.csv\")\n",
        "  product_subcats_df = pd.read_csv(at.folder_path / \"product_subcats.csv\")\n",
        "  territories_df = pd.read_csv(at.folder_path / \"territories.csv\")\n",
        "  sales_2021_df = pd.read_csv(at.folder_path / \"sales_2021.csv\")\n",
        "  returns_df = pd.read_csv(at.folder_path / \"returns.csv\")\n",
        "  sales_2020_df = pd.read_csv(at.folder_path / \"sales_2020.csv\")\n",
        "  product_cats_df = pd.read_csv(at.folder_path / \"product_cats.csv\")\n",
        "  customers_df = pd.read_csv(at.folder_path / \"customers.csv\")\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B.1 Fixing \"Data type conversion and encoding preparation\""
      ],
      "metadata": {
        "id": "bII_PglX5E-r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaR8p5n8hez4"
      },
      "outputs": [],
      "source": [
        "print(\"=== Data Type Preparation for Clustering ===\\n\")\n",
        "\n",
        "df_clean = X_selected.copy()\n",
        "\n",
        "print(\"Current data types:\")\n",
        "print(df_clean.dtypes)\n",
        "\n",
        "categorical_columns = ['marital_status', 'education_level', 'occupation', 'homeowner',\n",
        "                      'age_group', 'income_category', 'lifestyle_segment', 'family_status', 'value_segment']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    df_clean[col] = df_clean[col].astype('category')\n",
        "\n",
        "print(f\"\\nAfter conversion - Categorical columns: {len(categorical_columns)}\")\n",
        "print(f\"Numerical columns: {len(df_clean.select_dtypes(include=['number']).columns)}\")\n",
        "\n",
        "print(\"\\nData types after conversion:\")\n",
        "print(df_clean.dtypes.value_counts())\n",
        "\n",
        "print(f\"\\nCleaned dataset shape: {df_clean.shape}\")\n",
        "print(\"Sample of cleaned data:\")\n",
        "display(df_clean.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MP7lpNL0LZBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cleaning_1_explanations = \"\"\"\n",
        "Issue: Data type standardization for clustering algorithms\n",
        "Action: Converted categorical columns to proper 'category' data type\n",
        "\n",
        "Reason:\n",
        "- Clustering algorithms require consistent data types\n",
        "- Categorical data type improves memory efficiency and processing speed\n",
        "- Enables proper encoding in subsequent steps\n",
        "- Facilitates one-hot encoding for categorical variables\n",
        "\n",
        "Impact:\n",
        "- Reduced memory usage\n",
        "- Improved data processing performance\n",
        "- Prepared data for proper encoding techniques\n",
        "- Maintained data integrity for clustering algorithms\n",
        "\n",
        "Business Justification: Proper data typing ensures accurate distance calculations in clustering algorithms, leading to more meaningful customer segments.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "dNo--8IgPzhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='data_cleaning_1_explanations', value=data_cleaning_1_explanations)"
      ],
      "metadata": {
        "id": "cz_yVvA-Pzkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B.2 Fixing \"Handling categorical variables for clustering\""
      ],
      "metadata": {
        "id": "wRJ6Ql1F5ODe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsTzKV3bhez4"
      },
      "outputs": [],
      "source": [
        "print(\"=== Categorical Variables Analysis for Encoding ===\\n\")\n",
        "\n",
        "categorical_columns = ['marital_status', 'education_level', 'occupation', 'homeowner',\n",
        "                      'age_group', 'income_category', 'lifestyle_segment', 'family_status', 'value_segment']\n",
        "\n",
        "print(\"Categorical variables cardinality:\")\n",
        "for col in categorical_columns:\n",
        "    unique_count = df_clean[col].nunique()\n",
        "    unique_values = df_clean[col].unique()\n",
        "    print(f\"  {col:20}: {unique_count:2} categories - {list(unique_values)}\")\n",
        "\n",
        "print(\"\\nCategorical Variable Types:\")\n",
        "ordinal_vars = {\n",
        "    'education_level': ['Partial High School', 'High School', 'Partial College', 'Bachelors', 'Graduate Degree'],\n",
        "    'income_category': ['Low Income', 'Middle Income', 'Upper Middle Income', 'High Income'],\n",
        "    'value_segment': ['Standard Value', 'Medium Value', 'High Value', 'Premium'],\n",
        "    'age_group': ['Young Adult', 'Adult', 'Middle Age', 'Senior', 'Elderly']\n",
        "}\n",
        "\n",
        "nominal_vars = ['marital_status', 'occupation', 'homeowner', 'lifestyle_segment', 'family_status']\n",
        "\n",
        "print(\"Ordinal variables (inherent order):\")\n",
        "for var in ordinal_vars:\n",
        "    print(f\"  - {var}: {ordinal_vars[var]}\")\n",
        "\n",
        "print(\"\\nNominal variables (no inherent order):\")\n",
        "for var in nominal_vars:\n",
        "    print(f\"  - {var}: {df_clean[var].unique().tolist()}\")\n",
        "\n",
        "print(f\"\\nTotal: {len(ordinal_vars)} ordinal, {len(nominal_vars)} nominal categorical variables\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LZwEVfkqLcwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cleaning_2_explanations = \"\"\"\n",
        "Issue: Categorical variable analysis for appropriate encoding\n",
        "Action: Analyzed and classified categorical variables as ordinal vs nominal\n",
        "\n",
        "Analysis Results:\n",
        "- 4 Ordinal variables with inherent order:\n",
        "  * education_level (5 levels: Partial High School → Graduate Degree)\n",
        "  * income_category (4 levels: Low → High Income)\n",
        "  * value_segment (4 levels: Standard → Premium)\n",
        "  * age_group (5 levels: Young Adult → Elderly)\n",
        "\n",
        "- 5 Nominal variables without inherent order:\n",
        "  * marital_status (M, S)\n",
        "  * occupation (5 categories)\n",
        "  * homeowner (Y, N)\n",
        "  * lifestyle_segment (5 categories)\n",
        "  * family_status (4 categories)\n",
        "\n",
        "Encoding Strategy:\n",
        "- Ordinal variables: Use label encoding to preserve order information\n",
        "- Nominal variables: Use one-hot encoding to avoid artificial ordering\n",
        "\n",
        "Impact: Proper encoding preserves the semantic meaning of categorical data and improves clustering quality by maintaining appropriate distance relationships between categories.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zbp9FGOPP7UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='data_cleaning_2_explanations', value=data_cleaning_2_explanations)"
      ],
      "metadata": {
        "id": "51A_eWA0P7W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B.3 Fixing \"Data consistency checks\""
      ],
      "metadata": {
        "id": "qhu0LRMi5PgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Data Consistency and Validation Checks ===\\n\")\n",
        "\n",
        "print(\"1. Age vs Age Group Consistency:\")\n",
        "age_group_mapping = {\n",
        "    'Young Adult': (18, 34),\n",
        "    'Adult': (35, 49),\n",
        "    'Middle Age': (50, 64),\n",
        "    'Senior': (65, 79),\n",
        "    'Elderly': (80, 120)\n",
        "}\n",
        "\n",
        "inconsistent_age_groups = []\n",
        "for idx, row in df_clean.iterrows():\n",
        "    age = row['age']\n",
        "    age_group = row['age_group']\n",
        "    expected_range = age_group_mapping.get(age_group, (0, 0))\n",
        "    if not (expected_range[0] <= age <= expected_range[1]):\n",
        "        inconsistent_age_groups.append((idx, age, age_group, expected_range))\n",
        "\n",
        "if inconsistent_age_groups:\n",
        "    print(f\"  Found {len(inconsistent_age_groups)} inconsistent age-group pairs\")\n",
        "    print(\"  Sample inconsistencies:\")\n",
        "    for idx, age, age_group, expected in inconsistent_age_groups[:5]:\n",
        "        print(f\"    Row {idx}: Age={age}, Group='{age_group}', Expected range={expected}\")\n",
        "else:\n",
        "    print(\"  ✓ All age-group pairs are consistent\")\n",
        "\n",
        "print(\"\\n2. Income vs Income Category Consistency:\")\n",
        "income_category_ranges = {\n",
        "    'Low Income': (10000, 29999),\n",
        "    'Middle Income': (30000, 59999),\n",
        "    'Upper Middle Income': (60000, 99999),\n",
        "    'High Income': (100000, 170000)\n",
        "}\n",
        "\n",
        "inconsistent_incomes = []\n",
        "for idx, row in df_clean.iterrows():\n",
        "    income = row['annual_income']\n",
        "    income_cat = row['income_category']\n",
        "    expected_range = income_category_ranges.get(income_cat, (0, 0))\n",
        "    if not (expected_range[0] <= income <= expected_range[1]):\n",
        "        inconsistent_incomes.append((idx, income, income_cat, expected_range))\n",
        "\n",
        "if inconsistent_incomes:\n",
        "    print(f\"  Found {len(inconsistent_incomes)} inconsistent income-category pairs\")\n",
        "    print(\"  Sample inconsistencies:\")\n",
        "    for idx, income, income_cat, expected in inconsistent_incomes[:5]:\n",
        "        print(f\"    Row {idx}: Income={income}, Category='{income_cat}', Expected range={expected}\")\n",
        "else:\n",
        "    print(\"  ✓ All income-category pairs are consistent\")\n",
        "\n",
        "print(\"\\n3. Family Status vs Dependents/Marital Status Consistency:\")\n",
        "inconsistent_family = []\n",
        "for idx, row in df_clean.iterrows():\n",
        "    family_status = row['family_status']\n",
        "    marital_status = row['marital_status']\n",
        "    dependents = row['number_dependents']\n",
        "\n",
        "    if family_status == 'Single No Kids' and (marital_status != 'S' or dependents != 0):\n",
        "        inconsistent_family.append((idx, family_status, marital_status, dependents))\n",
        "    elif family_status == 'Single Parent' and (marital_status != 'S' or dependents == 0):\n",
        "        inconsistent_family.append((idx, family_status, marital_status, dependents))\n",
        "    elif family_status == 'Married No Kids' and (marital_status != 'M' or dependents != 0):\n",
        "        inconsistent_family.append((idx, family_status, marital_status, dependents))\n",
        "    elif family_status == 'Married With Kids' and (marital_status != 'M' or dependents == 0):\n",
        "        inconsistent_family.append((idx, family_status, marital_status, dependents))\n",
        "\n",
        "if inconsistent_family:\n",
        "    print(f\"  Found {len(inconsistent_family)} inconsistent family status pairs\")\n",
        "    print(\"  Sample inconsistencies:\")\n",
        "    for idx, family, marital, deps in inconsistent_family[:5]:\n",
        "        print(f\"    Row {idx}: Family='{family}', Marital='{marital}', Dependents={deps}\")\n",
        "else:\n",
        "    print(\"  ✓ All family status pairs are consistent\")\n",
        "\n",
        "print(f\"\\nOverall data quality: {df_clean.shape[0] - len(inconsistent_age_groups) - len(inconsistent_incomes) - len(inconsistent_family)}/{df_clean.shape[0]} rows consistent\")\n",
        "\n",
        "print(\"\\n4. Data Type Preparation for Clustering:\")\n",
        "\n",
        "print(\"Current data types:\")\n",
        "print(df_clean.dtypes)\n",
        "\n",
        "categorical_columns = ['marital_status', 'education_level', 'occupation', 'homeowner',\n",
        "                      'age_group', 'income_category', 'lifestyle_segment', 'family_status', 'value_segment']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    if col in df_clean.columns:\n",
        "        df_clean[col] = df_clean[col].astype('category')\n",
        "        print(f\"  - {col}: converted to category\")\n",
        "\n",
        "numerical_columns = ['age', 'number_dependents', 'annual_income']\n",
        "for col in numerical_columns:\n",
        "    if col in df_clean.columns:\n",
        "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
        "        print(f\"  - {col}: ensured numeric type\")\n",
        "\n",
        "print(f\"\\nFinal data types after conversion:\")\n",
        "print(df_clean.dtypes.value_counts())\n",
        "print(f\"Dataset shape: {df_clean.shape}\")\n",
        "\n",
        "print(\"\\nSample of cleaned data:\")\n",
        "display(df_clean.head(2))"
      ],
      "metadata": {
        "id": "eJh1KWoF5Qze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dMKB2aKLLhEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cleaning_3_explanations = \"\"\"\n",
        "Issue: Data consistency validation and type preparation\n",
        "Action:\n",
        "- Performed cross-validation checks between related features\n",
        "- Converted categorical variables to efficient 'category' data type\n",
        "- Ensured numerical variables are properly typed\n",
        "\n",
        "Validation Results:\n",
        "- All age-group pairs consistent ✓\n",
        "- All income-category pairs consistent ✓\n",
        "- All family status pairs consistent ✓\n",
        "- 100% data consistency achieved\n",
        "\n",
        "Data Type Preparation:\n",
        "- 9 categorical variables converted to 'category' type for efficiency\n",
        "- 3 numerical variables ensured to be proper numeric types\n",
        "- All data now properly typed for subsequent encoding and clustering\n",
        "\n",
        "Importance: Consistent and properly typed data ensures accurate feature encoding and reliable clustering results. Data consistency checks validate that engineered features logically align with their source data.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "HHPbgT_PP_5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='data_cleaning_3_explanations', value=data_cleaning_3_explanations)"
      ],
      "metadata": {
        "id": "Pr9WS8jbP__p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B.n Fixing \"\\<describe_issue_here\\>\"\n",
        "\n",
        "> You can add more cells related to other issues in this section"
      ],
      "metadata": {
        "id": "VrxmkcJNLiFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section and then remove this comment>"
      ],
      "metadata": {
        "id": "WIL-U_qlLiMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85n-2YC-_c2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section and then remove this comment>\n",
        "data_cleaning_n_explanations = \"\"\"\n",
        "Provide some explanations on why you believe it is important to fix this issue and its impacts\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "octqRnEF_dAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='data_cleaning_n_explanations', value=data_cleaning_n_explanations)"
      ],
      "metadata": {
        "id": "WEy5hyRy_dQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## C. Feature Engineering"
      ],
      "metadata": {
        "id": "Z9jsWz-z5-XS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "# Create copy of datasets\n",
        "\n",
        "try:\n",
        "  training_df_clean = df_clean.copy()\n",
        "  validation_df_clean = df_clean.copy()\n",
        "  testing_df_clean = df_clean.copy()\n",
        "  training_df_eng = training_df_clean.copy()\n",
        "  validation_df_eng = validation_df_clean.copy()\n",
        "  testing_df_eng = testing_df_clean.copy()\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "id": "viLWliu76Fm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C.1 New Feature \"Encoded categorical variables\"\n",
        "\n"
      ],
      "metadata": {
        "id": "imwl7ISs6O0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Categorical Variables Encoding ===\\n\")\n",
        "\n",
        "df_eng = df_clean.copy()\n",
        "\n",
        "ordinal_mappings = {\n",
        "    'education_level': {\n",
        "        'Partial High School': 1,\n",
        "        'High School': 2,\n",
        "        'Partial College': 3,\n",
        "        'Bachelors': 4,\n",
        "        'Graduate Degree': 5\n",
        "    },\n",
        "    'income_category': {\n",
        "        'Low Income': 1,\n",
        "        'Middle Income': 2,\n",
        "        'Upper Middle Income': 3,\n",
        "        'High Income': 4\n",
        "    },\n",
        "    'value_segment': {\n",
        "        'Standard Value': 1,\n",
        "        'Medium Value': 2,\n",
        "        'High Value': 3,\n",
        "        'Premium': 4\n",
        "    },\n",
        "    'age_group': {\n",
        "        'Young Adult': 1,\n",
        "        'Adult': 2,\n",
        "        'Middle Age': 3,\n",
        "        'Senior': 4,\n",
        "        'Elderly': 5\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Applying ordinal encoding to categorical variables:\")\n",
        "for col, mapping in ordinal_mappings.items():\n",
        "    df_eng[f'{col}_encoded'] = df_eng[col].map(mapping)\n",
        "    print(f\"  - {col} → {col}_encoded: {mapping}\")\n",
        "\n",
        "nominal_vars = ['marital_status', 'occupation', 'homeowner', 'lifestyle_segment', 'family_status']\n",
        "\n",
        "print(f\"\\nNominal variables ready for one-hot encoding: {nominal_vars}\")\n",
        "print(f\"Total features after ordinal encoding: {df_eng.shape[1]}\")\n",
        "\n",
        "print(\"\\nSample of encoded data:\")\n",
        "encoded_sample = df_eng[['education_level', 'education_level_encoded',\n",
        "                        'income_category', 'income_category_encoded',\n",
        "                        'value_segment', 'value_segment_encoded']].head(3)\n",
        "display(encoded_sample)"
      ],
      "metadata": {
        "id": "t5RVBQKW6mJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F1u712T5Lr04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_engineering_1_explanations = \"\"\"\n",
        "New Feature: Encoded categorical variables for ordinal features\n",
        "Action: Applied label encoding to preserve ordinal relationships in categorical variables\n",
        "\n",
        "Encoded Variables:\n",
        "- education_level_encoded: Maps education levels from 1 (Partial High School) to 5 (Graduate Degree)\n",
        "- income_category_encoded: Maps income categories from 1 (Low Income) to 4 (High Income)\n",
        "- value_segment_encoded: Maps value segments from 1 (Standard Value) to 4 (Premium)\n",
        "- age_group_encoded: Maps age groups from 1 (Young Adult) to 5 (Elderly)\n",
        "\n",
        "Rationale:\n",
        "- Preserves the inherent order information in ordinal categorical variables\n",
        "- Enables clustering algorithms to understand hierarchical relationships\n",
        "- Maintains the semantic meaning of ordered categories\n",
        "- More efficient than one-hot encoding for ordinal data\n",
        "\n",
        "Impact: Clustering algorithms can now properly interpret the progression from low to high education, income, value, and age groups, leading to more meaningful segment boundaries.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "M-kYSZDfQFks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_engineering_1_explanations', value=feature_engineering_1_explanations)"
      ],
      "metadata": {
        "id": "25d_SMvaQFr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C.2 New Feature \"One-hot encoded nominal variables\"\n",
        "\n"
      ],
      "metadata": {
        "id": "jYxCnW3C6zJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== One-Hot Encoding for Nominal Variables ===\\n\")\n",
        "\n",
        "nominal_vars = ['marital_status', 'occupation', 'homeowner', 'lifestyle_segment', 'family_status']\n",
        "\n",
        "print(\"Applying one-hot encoding to nominal variables:\")\n",
        "df_encoded = pd.get_dummies(df_eng, columns=nominal_vars, prefix=nominal_vars, drop_first=True)\n",
        "\n",
        "print(f\"Original features: {df_eng.shape[1]}\")\n",
        "print(f\"After one-hot encoding: {df_encoded.shape[1]}\")\n",
        "\n",
        "one_hot_columns = [col for col in df_encoded.columns if any(nom in col for nom in nominal_vars)]\n",
        "print(f\"\\nGenerated {len(one_hot_columns)} one-hot encoded columns:\")\n",
        "for i, col in enumerate(one_hot_columns[:10], 1):\n",
        "    print(f\"  {i:2d}. {col}\")\n",
        "if len(one_hot_columns) > 10:\n",
        "    print(f\"  ... and {len(one_hot_columns) - 10} more\")\n",
        "\n",
        "print(f\"\\nFinal encoded dataset shape: {df_encoded.shape}\")\n",
        "print(\"\\nSample of one-hot encoded data (showing first 5 encoded columns):\")\n",
        "sample_encoded = df_encoded[one_hot_columns[:5]].head(3)\n",
        "display(sample_encoded)"
      ],
      "metadata": {
        "id": "y03X8eeW6zbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HcSkZYwbLuqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_engineering_2_explanations = \"\"\"\n",
        "New Feature: One-hot encoded nominal variables\n",
        "Action: Applied one-hot encoding to nominal categorical variables without inherent order\n",
        "\n",
        "Encoded Variables:\n",
        "- marital_status: Converted to binary columns (drop_first=True)\n",
        "- occupation: 5 categories → 4 binary columns\n",
        "- homeowner: 2 categories → 1 binary column\n",
        "- lifestyle_segment: 5 categories → 4 binary columns\n",
        "- family_status: 4 categories → 3 binary columns\n",
        "\n",
        "Rationale:\n",
        "- Prevents clustering algorithms from imposing artificial order on nominal categories\n",
        "- Each category gets equal weight in distance calculations\n",
        "- Avoids the \"distance\" misconception between unrelated categories\n",
        "- drop_first=True removes redundancy and reduces multicollinearity\n",
        "\n",
        "Impact:\n",
        "- Expanded feature space from 16 to [number] features\n",
        "- Enabled proper representation of categorical relationships\n",
        "- Prepared data for distance-based clustering algorithms like K-Means\n",
        "- Maintained interpretability through meaningful column names\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UVtR91G3QLVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_engineering_2_explanations', value=feature_engineering_2_explanations)"
      ],
      "metadata": {
        "id": "PMH2cyXzQLYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C.4 New Feature \"\\<put_name_here\\>\"\n",
        "\n"
      ],
      "metadata": {
        "id": "gWF4jvXb62kU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Feature scaling will be applied in the data transformation section\")\n",
        "print(\"This ensures all features are on comparable scales for clustering algorithms\")"
      ],
      "metadata": {
        "id": "dfXFMHqw62r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9iuqF2MBLwKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_engineering_3_explanations = \"\"\"\n",
        "Note: Feature Scaling Preparation\n",
        "Purpose: Acknowledging that feature scaling is essential for clustering algorithms\n",
        "\n",
        "Rationale:\n",
        "- Clustering algorithms like K-Means are distance-based\n",
        "- Features with larger scales can dominate the distance calculations\n",
        "- Standardization/Normalization ensures all features contribute equally\n",
        "\n",
        "Next Steps:\n",
        "- Scaling will be applied in Section D (Data Transformation)\n",
        "- This separation maintains clean workflow organization\n",
        "- Allows flexibility to test different scaling approaches\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ai9-L0dnQPvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_engineering_3_explanations', value=feature_engineering_3_explanations)"
      ],
      "metadata": {
        "id": "okaLOh0SQP1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C.n Fixing \"\\<describe_issue_here\\>\"\n",
        "\n",
        "> You can add more cells related to new features in this section"
      ],
      "metadata": {
        "id": "l9Eh63GQLw4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section and then remove this comment>"
      ],
      "metadata": {
        "id": "SZjz6x6vLw-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8GTtThsR_Nhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section and then remove this comment>\n",
        "feature_engineering_n_explanations = \"\"\"\n",
        "Provide some explanations on why you believe it is important to create this feature and its impacts\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GCgD5TwA_NrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='feature_engineering_n_explanations', value=feature_engineering_n_explanations)"
      ],
      "metadata": {
        "id": "q-H6x7Tf_N0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0S5LSAcjkvP"
      },
      "source": [
        "---\n",
        "## D. Data Preparation for Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D.1 Split Datasets\n"
      ],
      "metadata": {
        "id": "JOCutkG6k3GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Final Dataset Preparation for Clustering ===\\n\")\n",
        "\n",
        "\n",
        "clustering_features = [col for col in df_encoded.columns if col not in [\n",
        "    'education_level', 'income_category', 'value_segment', 'age_group',\n",
        "    'marital_status', 'occupation', 'homeowner', 'lifestyle_segment', 'family_status'\n",
        "]]\n",
        "\n",
        "X_final = df_encoded[clustering_features]\n",
        "\n",
        "print(f\"Final feature set: {len(clustering_features)} features\")\n",
        "print(f\"Final dataset shape: {X_final.shape}\")\n",
        "\n",
        "numerical_features = ['age', 'number_dependents', 'annual_income']\n",
        "ordinal_encoded = [col for col in clustering_features if 'encoded' in col]\n",
        "one_hot_encoded = [col for col in clustering_features if col not in numerical_features and col not in ordinal_encoded]\n",
        "\n",
        "print(f\"\\nFeature Categories:\")\n",
        "print(f\"- Numerical features: {len(numerical_features)}\")\n",
        "print(f\"- Ordinal encoded: {len(ordinal_encoded)}\")\n",
        "print(f\"- One-hot encoded: {len(one_hot_encoded)}\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_temp, X_test = train_test_split(X_final, test_size=0.1, random_state=42)\n",
        "\n",
        "X_train, X_val = train_test_split(X_temp, test_size=0.111, random_state=42)\n",
        "\n",
        "print(f\"\\nData splits created:\")\n",
        "print(f\"Training set: {X_train.shape} ({len(X_train)/len(X_final)*100:.1f}%)\")\n",
        "print(f\"Validation set: {X_val.shape} ({len(X_val)/len(X_final)*100:.1f}%)\")\n",
        "print(f\"Testing set: {X_test.shape} ({len(X_test)/len(X_final)*100:.1f}%)\")\n",
        "\n",
        "training_df_eng = X_train.copy()\n",
        "validation_df_eng = X_val.copy()\n",
        "testing_df_eng = X_test.copy()\n",
        "\n",
        "print(\"\\nGlobal dataset variables updated successfully\")"
      ],
      "metadata": {
        "id": "XfWFHXOik5aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmPVLaNulC1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_splitting_explanations = \"\"\"\n",
        "Data Splitting Strategy for Customer Clustering:\n",
        "\n",
        "Split Ratio: 80% Training - 10% Validation - 10% Testing\n",
        "\n",
        "Rationale for Clustering:\n",
        "- Training Set (80%): Used for developing clustering models, determining optimal number of clusters (elbow method, silhouette analysis)\n",
        "- Validation Set (10%): Used for validating cluster stability and consistency across different data samples\n",
        "- Testing Set (10%): Reserved for final evaluation to ensure clusters generalize well to unseen data\n",
        "\n",
        "Feature Composition:\n",
        "- 21 total features ready for clustering\n",
        "- All features are numerical after comprehensive encoding\n",
        "- Mix of original numerical, ordinal encoded, and one-hot encoded variables\n",
        "\n",
        "Clustering Approach:\n",
        "While clustering typically uses entire datasets, this split allows for robust validation of cluster quality and stability, ensuring our customer segments are meaningful and reproducible.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gZFFgktrlC7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='data_splitting_explanations', value=data_splitting_explanations)"
      ],
      "metadata": {
        "id": "nY914h0klDAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D.2 Data Transformation <put_name_here>\n"
      ],
      "metadata": {
        "id": "RKqt6BN6csNC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PnGwsy2hez4"
      },
      "outputs": [],
      "source": [
        "print(\"=== Feature Scaling for Clustering ===\\n\")\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "print(\"Fitting StandardScaler on training data...\")\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(\"Scaling completed successfully!\")\n",
        "print(f\"Scaled training set: {X_train_scaled_df.shape}\")\n",
        "print(f\"Scaled validation set: {X_val_scaled_df.shape}\")\n",
        "print(f\"Scaled testing set: {X_test_scaled_df.shape}\")\n",
        "\n",
        "print(\"\\nScaling verification:\")\n",
        "print(f\"Training mean: {X_train_scaled_df.mean().mean():.6f} (should be ~0)\")\n",
        "print(f\"Training std: {X_train_scaled_df.std().mean():.6f} (should be ~1)\")\n",
        "\n",
        "X_train_final = X_train_scaled_df\n",
        "X_val_final = X_val_scaled_df\n",
        "X_test_final = X_test_scaled_df\n",
        "\n",
        "print(\"\\n✅ All datasets scaled and ready for clustering algorithms!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v1itdkBNL7f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transformation_1_explanations = \"\"\"\n",
        "Transformation: StandardScaler (Z-score Normalization)\n",
        "\n",
        "Action Applied:\n",
        "- Fitted StandardScaler exclusively on training data (15971 samples)\n",
        "- Transformed training, validation, and testing sets using the fitted scaler\n",
        "- All 20 features were standardized to have mean = 0 and standard deviation = 1\n",
        "\n",
        "Verification Results:\n",
        "- Training set mean: 0.000000 (perfectly centered)\n",
        "- Training set standard deviation: 1.000031 (very close to ideal 1.0)\n",
        "- Validation and testing sets transformed using training set parameters\n",
        "\n",
        "Why StandardScaler for Clustering:\n",
        "1. Distance-Based Algorithms: Clustering methods like K-Means rely on Euclidean distance calculations\n",
        "2. Scale Sensitivity: Features with larger ranges (e.g., annual_income: 10,000-170,000) would dominate over smaller-range features (e.g., binary encoded variables: 0-1)\n",
        "3. Equal Contribution: Standardization ensures all features contribute equally to cluster formation\n",
        "4. Algorithm Performance: Prevents bias towards high-magnitude features, leading to more balanced and meaningful clusters\n",
        "\n",
        "Data Leakage Prevention:\n",
        "- Scaler was fitted ONLY on training data\n",
        "- Validation and test sets were transformed using training set parameters\n",
        "- This maintains the integrity of our evaluation process\n",
        "\n",
        "Impact on Clustering:\n",
        "- Enables fair distance comparisons across all feature types\n",
        "- Improves cluster quality and interpretability\n",
        "- Facilitates better convergence of clustering algorithms\n",
        "- Prepares data for optimal performance in subsequent clustering analysis\n",
        "\n",
        "The scaled datasets are now ready for baseline clustering model development.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "or7RgXjwQaAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='data_transformation_1_explanations', value=data_transformation_1_explanations)"
      ],
      "metadata": {
        "id": "f7EzJD6JQaF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D.3 Data Transformation <put_name_here>"
      ],
      "metadata": {
        "id": "Nl12P1VIdFGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"No additional data transformations required for clustering.\")\n",
        "print(\"All necessary preprocessing completed in previous steps:\")\n",
        "print(\"✓ Feature selection and encoding\")\n",
        "print(\"✓ Data standardization (StandardScaler)\")\n",
        "print(\"✓ Data ready for clustering algorithms\")"
      ],
      "metadata": {
        "id": "4LLUCGNPQhO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0FVb16jUL-Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transformation_2_explanations = \"\"\"\n",
        "Rationale for No Additional Transformations:\n",
        "\n",
        "Comprehensive Preprocessing Already Completed:\n",
        "1. Feature Selection (Section A): Selected 12 business-relevant features\n",
        "2. Data Encoding (Section C):\n",
        "   - Ordinal encoding for ordered categories\n",
        "   - One-hot encoding for nominal categories\n",
        "3. Data Standardization (D.2): All features scaled to comparable ranges\n",
        "\n",
        "Why No Further Transformations Needed:\n",
        "- Feature Count (20): Reasonable for clustering, no dimensionality reduction required\n",
        "- Data Quality: High consistency and proper typing achieved\n",
        "- Business Interpretability: Maintained original feature meanings\n",
        "- Clustering Readiness: All algorithms can work effectively with current data state\n",
        "\n",
        "The dataset is now optimally prepared for baseline clustering analysis and model development.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DGuIGxuFQhZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='data_transformation_2_explanations', value=data_transformation_2_explanations)"
      ],
      "metadata": {
        "id": "0fWVr_nAQhkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D.4 Data Transformation <put_name_here>\n"
      ],
      "metadata": {
        "id": "nw8W-JpHdGlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section and then remove this comment>"
      ],
      "metadata": {
        "id": "VE_NBoquQsuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3zcGQlfMCP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section and then remove this comment>\n",
        "data_transformation_3_explanations = \"\"\"\n",
        "Provide some explanations on why you believe it is important to perform this data transformation and its impacts\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RK-j77QRQsxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='data_transformation_3_explanations', value=data_transformation_3_explanations)"
      ],
      "metadata": {
        "id": "H0cpp9aCQs0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D.n Fixing \"\\<describe_issue_here\\>\"\n",
        "\n",
        "> You can add more cells related to data preparation in this section"
      ],
      "metadata": {
        "id": "fvT1FAD7MP6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section and then remove this comment>"
      ],
      "metadata": {
        "id": "YqbadwJ4MP_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RxQajLlx_Ci2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section and then remove this comment>\n",
        "data_transformation_n_explanations = \"\"\"\n",
        "Provide some explanations on why you believe it is important to perform this data transformation and its impacts\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "V5dYUfTV_Dja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "print_tile(size=\"h3\", key='data_transformation_n_explanations', value=data_transformation_n_explanations)"
      ],
      "metadata": {
        "id": "Wi0yK5kg_D8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## E. Save Datasets\n",
        "\n",
        "> Do not change this code"
      ],
      "metadata": {
        "id": "s0CJolMhdmLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THE CODE IN THIS CELL\n",
        "\n",
        "try:\n",
        "  X_train.to_csv(at.folder_path / 'X_train.csv', index=False)\n",
        "\n",
        "  X_val.to_csv(at.folder_path / 'X_val.csv', index=False)\n",
        "\n",
        "  X_test.to_csv(at.folder_path / 'X_test.csv', index=False)\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "id": "hwIgKOsGdrf3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}